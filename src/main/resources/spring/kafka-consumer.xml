<?xml version="1.0" encoding="UTF-8"?>
<beans xmlns="http://www.springframework.org/schema/beans"
       xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"
       xsi:schemaLocation="http://www.springframework.org/schema/beans
       http://www.springframework.org/schema/beans/spring-beans.xsd">

    <!-- 1、读取properties文件,配置多个properties配置文件 -->
    <bean id="propertyConfigurer" class="org.springframework.beans.factory.config.PropertyPlaceholderConfigurer" scope="prototype">
        <property name="location" value="classpath:properties/application.properties"/>
    </bean>

    <!-- 2、定义consumer的参数 -->
    <bean id="consumerProperties" class="java.util.HashMap">
        <constructor-arg>
            <map>
                <entry key="bootstrap.servers"          value="${kafka.consumer.bootstrap.servers}"/>
                <!-- 指定消费组名 -->
                <entry key="group.id"                   value="${kafka.consumer.group.id}"/>
                <!-- 自动提交开关(待定结论:当为false时,需配置ackMode,另外这里的autoCommit和下面服务实现类中的autoCommit有什么关系?) -->
                <entry key="enable.auto.commit"         value="${kafka.consumer.enable.auto.commit}" />
                <entry key="session.timeout.ms"         value="${kafka.consumer.session.timeout.ms}" />
                <entry key="auto.commit.interval.ms"    value="${kafka.consumer.auto.commit.interval.ms}" />
                <!-- 当使用批量处理消息的时候,每次onMessage方法获取到的消息总条数虽然是随机的,但是不会超过此最大值 -->
                <entry key="max.poll.records"           value="50"/>
                <entry key="retry.backoff.ms"           value="100" />
<!--                <entry key="key.deserializer"           value="org.apache.kafka.common.serialization.IntegerDeserializer"/>-->
                <entry key="key.deserializer"           value="${kafka.consumer.key.deserializer}" />
                <entry key="value.deserializer"         value="${kafka.consumer.value.deserializer}" />
            </map>
        </constructor-arg>
    </bean>

    <!-- 3、创建consumerFactory bean -->
    <bean id="consumerFactory" class="org.springframework.kafka.core.DefaultKafkaConsumerFactory">
        <constructor-arg ref="consumerProperties"/>
    </bean>

    <!-- 消费一、消费消息的服务实现类 -->
    <bean id="singleAutoKafkaConsumer" class="com.wang.project.demo.service.kafkaConsumer.TestSingleAutoKafkaConsumer"/>

    <!-- 消费一、消费者容器配置信息 -->
    <bean id="containerProperties" class="org.springframework.kafka.listener.config.ContainerProperties">
        <!-- 主题topic -->
        <constructor-arg value="${kafka.topic.name.default}"/>
        <property name="messageListener" ref="singleAutoKafkaConsumer"/>
        <!-- 提交offset,批量提交(当auto.commit开关为开时，默认的ack，当为关时，需配置这里) -->
        <property name="ackMode" value="MANUAL"/>
        <!-- 提交offset的方式,每调用一次，就立即commit -->
<!--        <property name="ackMode" value="MANUAL_IMMEDIATE"/>-->
    </bean>

    <!-- 单线程消息监听容器,每启动一个消费者客户端,只会开启一个线程来消费 -->
<!--    <bean id="messageListenerContainer" class="org.springframework.kafka.listener.KafkaMessageListenerContainer" init-method="doStart">-->
<!--        <constructor-arg ref="consumerFactory"/>-->
<!--        <constructor-arg ref="containerProperties"/>-->
<!--    </bean>-->

    <!-- 消费一、多线程消息监听容器,每启动一个消费者客户端,可以开启多个线程,开启多少个线程自己可以通过concurrency来指定 -->
    <bean id="messageListenerContainer" class="org.springframework.kafka.listener.ConcurrentMessageListenerContainer" init-method="doStart">
        <constructor-arg ref="consumerFactory"/>
        <constructor-arg ref="containerProperties"/>
        <!-- 并发数 -->
        <property name="concurrency" value="${kafka.consumer.concurrency}"/>
    </bean>

</beans>